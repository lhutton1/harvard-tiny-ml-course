{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0292689",
   "metadata": {},
   "source": [
    "# Quantization aware training\n",
    "\n",
    "Converting a model from float to int using this method can lead to improved accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9194078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcafd61",
   "metadata": {},
   "source": [
    "## Load dataset, define model and train\n",
    "This is as would normally happen without quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d0306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.3116 - accuracy: 0.9118 - val_loss: 0.1399 - val_accuracy: 0.9623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1531a5d90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "    keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train model initially with floating-point weights, then calibrate.\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images,\n",
    "          train_labels,\n",
    "          epochs=1,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ab962",
   "metadata": {},
   "source": [
    "## Quantize the model\n",
    "Quantize the model using quantization aware training. The resulting model is 'quantization aware' but not fully quantized as the weights are float32 instead of int8. On converting to a TFLite model we can fully quantize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f23c22ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "quantize_layer_3 (QuantizeLa (None, 28, 28)            3         \n",
      "_________________________________________________________________\n",
      "quant_reshape_3 (QuantizeWra (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "quant_conv2d_3 (QuantizeWrap (None, 26, 26, 12)        147       \n",
      "_________________________________________________________________\n",
      "quant_max_pooling2d_3 (Quant (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "quant_flatten_3 (QuantizeWra (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "quant_dense_3 (QuantizeWrapp (None, 10)                20295     \n",
      "=================================================================\n",
      "Total params: 20,448\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 38\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "q_aware_model = tfmot.quantization.keras.quantize_model(model)\n",
    "\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f68dee",
   "metadata": {},
   "source": [
    "## Calibrate model with quantization aware training and evaluate against baseline\n",
    "\n",
    "The accuracy of both the baseline and quantized model should be similar. Hence, quantizing the model has little impact on performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57537e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1409 - accuracy: 0.9633 - val_loss: 0.1865 - val_accuracy: 0.9600\n",
      "Baseline test accuracy: 0.9577000141143799\n",
      "Quant test accuracy: 0.9545000195503235\n"
     ]
    }
   ],
   "source": [
    "train_images_subset = train_images[0:1000]\n",
    "train_labels_subset = train_labels[0:1000]\n",
    "\n",
    "q_aware_model.fit(train_images_subset, \n",
    "                  train_labels_subset, \n",
    "                  batch_size=500,\n",
    "                  epochs=1,\n",
    "                  validation_split=0.1)\n",
    "\n",
    "_, baseline_model_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "_, q_aware_model_accuracy = q_aware_model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Quant test accuracy:', q_aware_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b794322",
   "metadata": {},
   "source": [
    "## Create fully quantized model in TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ba3de81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as reshape_3_layer_call_fn, reshape_3_layer_call_and_return_conditional_losses, conv2d_3_layer_call_fn, conv2d_3_layer_call_and_return_conditional_losses, flatten_3_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1c/v15_t4sj19x7p9fx5qk_h9hc0000gn/T/tmpo9hxb524/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1c/v15_t4sj19x7p9fx5qk_h9hc0000gn/T/tmpo9hxb524/assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b00898",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d523968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF accuracy: 0.9577000141143799\n",
      "Quant TF accuracy: 0.9545000195503235\n",
      "Quant TFLite accuracy: 0.9545\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0]['index']\n",
    "    output_index = interpreter.get_output_details()[0]['index']\n",
    "    prediction_digits = []\n",
    "    for i, test_image in enumerate(test_images):\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "    \n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    accuracy = (prediction_digits == test_labels).mean()\n",
    "    return accuracy\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('TF accuracy:', baseline_model_accuracy)\n",
    "print('Quant TF accuracy:', q_aware_model_accuracy)\n",
    "print('Quant TFLite accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65932970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
